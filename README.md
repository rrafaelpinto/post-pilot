# Post Pilot - Gerador de Posts LinkedIn com IA Multi-Provider

Sistema Django para gera√ß√£o de posts e artigos no LinkedIn utilizando **m√∫ltiplos provedores de IA** (OpenAI, Grok, Gemini) com processamento ass√≠ncrono via Celery.

## üöÄ Funcionalidades

- **Suporte Multi-AI**: OpenAI, Grok (X.AI) e Google Gemini üÜï
- **Gera√ß√£o de T√≥picos**: IA gera 3-5 t√≥picos estruturados para cada tema
- **Cria√ß√£o de Posts**: Gera posts simples (at√© 1300 caracteres) ou artigos longos
- **Melhoria de Conte√∫do**: Aprimora posts existentes com exemplos pr√°ticos e c√≥digo seguro
- **Processamento Ass√≠ncrono**: Utiliza Celery + Redis para chamadas de API n√£o bloqueantes
- **Interface Web Completa**: Dashboard para gerenciar temas, posts e visualizar estat√≠sticas
- **Renderiza√ß√£o Markdown**: Suporte completo a Markdown nos posts gerados
- **Monitoramento**: Interface Flower para acompanhar tarefas em tempo real
- **Troca de Provedores**: Sistema flex√≠vel para trocar entre diferentes AIs

## ü§ñ Provedores de IA Suportados

### OpenAI (GPT-4)
- **Modelos**: gpt-4o, gpt-4o-mini
- **Ponto forte**: Excelente qualidade geral, ampla compatibilidade
- **Status**: ‚úÖ Totalmente suportado

### Grok (X.AI) üÜï
- **Modelos**: grok-beta
- **Ponto forte**: Conhecimento atualizado, criado pela X (Twitter)
- **Status**: ‚úÖ Implementado (requer acesso beta)

### Google Gemini üÜï
- **Modelos**: gemini-1.5-pro
- **Ponto forte**: Boa integra√ß√£o com ecossistema Google
- **Status**: ‚úÖ Implementado

## üõ† Stack Tecnol√≥gica

- **Backend**: Django 5.2.5
- **IA**: OpenAI API, Grok API, Google Gemini API
- **Queue System**: Celery + Redis
- **Database**: SQLite (desenvolvimento) / PostgreSQL (produ√ß√£o)
- **Frontend**: Bootstrap 5.1.3
- **Monitoramento**: Flower
- **Markdown**: Python-Markdown

## üìã Pr√©-requisitos

- Python 3.11+
- Redis Server
- Conta na OpenAI com API Key

## üîß Instala√ß√£o e Configura√ß√£o

### 1. Clone o Reposit√≥rio
```bash
git clone <repository-url>
cd post-pilot
```

### 2. Configura√ß√£o do Ambiente Virtual
```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate     # Windows
```

### 3. Instala√ß√£o das Depend√™ncias
```bash
pip install django python-dotenv openai markdown
pip install celery redis django-celery-beat flower
```

### 4. Configura√ß√£o das Vari√°veis de Ambiente üÜï
```bash
cp .env.example .env
```

Edite o arquivo `.env` com suas configura√ß√µes:
```env
# AI Providers Configuration
DEFAULT_AI_PROVIDER=openai  # openai, grok, gemini

# OpenAI Configuration (requerido se usar openai)
OPENAI_API_KEY=sk-sua_chave_da_openai_aqui

# Grok (X.AI) Configuration (requerido se usar grok)
GROK_API_KEY=xai-sua_chave_do_grok_aqui

# Google Gemini Configuration (requerido se usar gemini)
GEMINI_API_KEY=sua_chave_do_gemini_aqui

# Celery Configuration
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Django Configuration
DEBUG=True
SECRET_KEY=sua_chave_secreta_aqui
```

### 5. Instala√ß√£o e Configura√ß√£o do Redis

#### Ubuntu/Debian:
```bash
sudo apt update
sudo apt install redis-server
sudo systemctl start redis-server
sudo systemctl enable redis-server
```

#### macOS (Homebrew):
```bash
brew install redis
brew services start redis
```

#### Windows:
Baixe e instale o Redis do [reposit√≥rio oficial](https://github.com/microsoftarchive/redis/releases)

### 6. Configura√ß√£o do Banco de Dados
```bash
python manage.py makemigrations
python manage.py migrate
python manage.py createsuperuser
```

## üöÄ Executando o Sistema

### M√©todo Recomendado: M√∫ltiplos Terminais

#### Terminal 1 - Django Server:
```bash
python manage.py runserver
```

#### Terminal 2 - Celery Worker:
```bash
./scripts/start_worker.sh
# ou manualmente:
celery -A post_pilot worker --loglevel=info --concurrency=2 --queues=default,ai_tasks
```

#### Terminal 3 - Celery Beat (Scheduler):
```bash
./scripts/start_beat.sh
# ou manualmente:
celery -A post_pilot beat --loglevel=info --scheduler django_celery_beat.schedulers:DatabaseScheduler
```

#### Terminal 4 - Flower (Monitoramento):
```bash
./scripts/start_flower.sh
# ou manualmente:
celery -A post_pilot flower --port=5555
```

### Acessos:
- **Aplica√ß√£o Web**: http://localhost:8000
- **Admin Django**: http://localhost:8000/admin
- **Flower (Monitoramento)**: http://localhost:5555

## ü§ñ Gerenciamento de Provedores de IA

### Comandos de Gerenciamento

#### Listar provedores dispon√≠veis:
```bash
python manage.py ai_provider --list
```

#### Ver provedor atual:
```bash
python manage.py ai_provider --current
```

#### Trocar provedor:
```bash
python manage.py ai_provider --set openai   # Para OpenAI
python manage.py ai_provider --set grok     # Para Grok (X.AI)
python manage.py ai_provider --set gemini   # Para Google Gemini
```

#### Testar conex√£o:
```bash
python manage.py ai_provider --test openai
python manage.py ai_provider --test grok
python manage.py ai_provider --test gemini
```

### Como Obter Chaves de API

#### OpenAI:
1. Acesse [platform.openai.com](https://platform.openai.com/)
2. Crie uma conta e adicione m√©todo de pagamento
3. V√° para "API Keys" e crie uma nova chave
4. Adicione cr√©ditos √† sua conta

#### Grok (X.AI):
1. Acesse [x.ai](https://x.ai/)
2. Solicite acesso √† API (ainda em beta limitado)
3. Aguarde aprova√ß√£o da equipe X.AI

#### Google Gemini:
1. Acesse [ai.google.dev](https://ai.google.dev/)
2. Crie um projeto no Google AI Studio
3. Gere uma chave de API
4. Tier gratuito dispon√≠vel com limita√ß√µes

### Teste de Configura√ß√£o

Execute o script de teste inclu√≠do:
```bash
python test_multi_ai.py
```

Isso ir√°:
- Verificar todos os provedores configurados
- Testar conex√µes com APIs
- Validar gera√ß√£o de t√≥picos
- Mostrar status da configura√ß√£o

## üìñ Como Usar

### 1. Criar um Tema
1. Acesse o dashboard
2. Clique em "Criar Novo Tema"
3. Digite o t√≠tulo do tema (ex: "React Hooks", "Python FastAPI", "Docker")

### 2. Gerar T√≥picos
1. Na p√°gina do tema, clique em "Gerar T√≥picos"
2. A IA criar√° 3-5 t√≥picos estruturados com hooks, resumos e CTAs
3. O processamento √© ass√≠ncrono - voc√™ pode acompanhar via Flower

### 3. Criar Posts
1. Para cada t√≥pico, escolha:
   - **Post Simples**: At√© 1300 caracteres, otimizado para LinkedIn
   - **Artigo**: 1000-1500 palavras + post promocional
2. O conte√∫do √© gerado em formato Markdown

### 4. Melhorar Posts
1. Na p√°gina do post, clique em "Melhorar Post"
2. A IA expandir√° o conte√∫do com:
   - Exemplos pr√°ticos de c√≥digo
   - Explica√ß√µes detalhadas
   - Considera√ß√µes de seguran√ßa
   - Boas pr√°ticas

## üîÑ Arquitetura Ass√≠ncrona

### Fluxo de Processamento:
1. **Interface Web** ‚Üí Dispara tarefa Celery
2. **Redis** ‚Üí Armazena a tarefa na fila
3. **Celery Worker** ‚Üí Processa chamada √† OpenAI API
4. **Resultado** ‚Üí Atualiza o banco de dados
5. **Interface** ‚Üí Exibe resultado ou status

### Filas Configuradas:
- `default`: Tarefas gerais
- `ai_tasks`: Chamadas espec√≠ficas para OpenAI (isoladas)

### Retry Strategy:
- **M√°ximo**: 3 tentativas
- **Delay**: Progressivo (60s, 120s, 180s)
- **Timeout**: 10 minutos por tarefa

## üìä Monitoramento com Flower

Acesse http://localhost:5555 para:
- Visualizar tarefas em execu√ß√£o
- Acompanhar filas e workers
- Ver hist√≥rico de execu√ß√µes
- Monitorar performance

## üîß Configura√ß√µes Avan√ßadas

### Modelos OpenAI Utilizados:
- **T√≥picos**: GPT-4o-mini (econ√¥mico e r√°pido)
- **Posts Simples**: GPT-4o-mini
- **Artigos**: GPT-4o (maior qualidade)
- **Melhorias**: GPT-4o (melhor an√°lise)

### Configura√ß√µes de Performance:
```python
# settings.py
CELERY_WORKER_PREFETCH_MULTIPLIER = 1
CELERY_TASK_SOFT_TIME_LIMIT = 300  # 5 minutos
CELERY_TASK_TIME_LIMIT = 600       # 10 minutos
```

## üêõ Troubleshooting

### Redis n√£o conecta:
```bash
# Verificar se Redis est√° rodando
redis-cli ping  # Deve retornar "PONG"

# Verificar porta
sudo netstat -tlnp | grep :6379
```

### Celery Worker n√£o inicia:
```bash
# Verificar logs
celery -A post_pilot worker --loglevel=debug

# Verificar configura√ß√µes
python manage.py shell
>>> from django.conf import settings
>>> print(settings.CELERY_BROKER_URL)
```

### OpenAI API Timeout:
```bash
# Verificar API Key
python manage.py shell
>>> import os
>>> print(os.getenv('OPENAI_API_KEY'))
```

## üìù Estrutura de Dados

### Theme Model:
- `title`: T√≠tulo do tema
- `suggested_topics`: T√≥picos gerados pela IA (JSON)
- `processing_status`: Status do processamento ass√≠ncrono

### Post Model:
- `post_type`: 'simple' ou 'article'
- `content`: Conte√∫do em Markdown
- `promotional_post`: Post promocional (apenas artigos)
- `processing_status`: Status do processamento ass√≠ncrono

## üöÄ Produ√ß√£o

### Configura√ß√µes Recomendadas:
```bash
# PostgreSQL
pip install psycopg2-binary

# Gunicorn
pip install gunicorn

# Supervisor para gerenciar processos
sudo apt install supervisor
```

### Docker Compose (Opcional):
```yaml
version: '3.8'
services:
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
  
  worker:
    build: .
    command: celery -A post_pilot worker
    depends_on:
      - redis
```

## üìÑ Licen√ßa

Este projeto est√° sob licen√ßa MIT. Veja o arquivo LICENSE para mais detalhes.

## ü§ù Contribui√ß√µes

Contribui√ß√µes s√£o bem-vindas! Por favor:
1. Fa√ßa um fork do projeto
2. Crie uma branch para sua feature
3. Commit suas mudan√ßas
4. Push para a branch
5. Abra um Pull Request

## üÜò Suporte

Para d√∫vidas e suporte:
- Abra uma issue no GitHub
- Consulte a documenta√ß√£o do Django
- Verifique a documenta√ß√£o do Celery

---

**Desenvolvido com ‚ù§Ô∏è para otimizar a cria√ß√£o de conte√∫do t√©cnico no LinkedIn**

Sistema Django para gera√ß√£o autom√°tica de postagens para LinkedIn usando OpenAI.

## Funcionalidades

- **Gest√£o de Temas**: Crie temas para suas postagens
- **Gera√ß√£o de T√≥picos**: Use IA para gerar 3-5 t√≥picos relevantes baseados no tema
- **Gera√ß√£o de Conte√∫do**: Crie posts simples ou artigos baseados nos t√≥picos
- **Tipos de Conte√∫do**: 
  - Posts simples (at√© 1300 caracteres)
  - Artigos (800-1200 palavras)
- **SEO**: T√≠tulo e descri√ß√£o otimizados para cada post
- **Status de Publica√ß√£o**: Rascunho, Gerado, Publicado, Agendado

## Instala√ß√£o

1. Clone o reposit√≥rio
2. Instale as depend√™ncias:
```bash
pip install django openai python-dotenv
```

3. Configure a chave da OpenAI no arquivo `.env`:
```
OPENAI_API_KEY=sua_chave_aqui
```

4. Execute as migra√ß√µes:
```bash
python manage.py makemigrations
python manage.py migrate
```

5. Crie um superusu√°rio:
```bash
python manage.py createsuperuser
```

6. Execute o servidor:
```bash
python manage.py runserver
```

## Uso

### 1. Criar um Tema
- Acesse `/themes/create/`
- Defina t√≠tulo e descri√ß√£o detalhada do tema
- O tema servir√° como base para gera√ß√£o de t√≥picos

### 2. Gerar T√≥picos
- Na p√°gina do tema, clique em "Gerar T√≥picos"
- A IA ir√° sugerir 3-5 t√≥picos relevantes
- Os t√≥picos ficam salvos no tema

### 3. Gerar Posts
- Selecione um t√≥pico gerado
- Escolha o tipo (Post Simples ou Artigo)
- A IA ir√° criar o conte√∫do completo
- Cada tema pode ter 1 artigo + 1 post simples

### 4. Gerenciar Posts
- Edite o conte√∫do gerado se necess√°rio
- Defina status (rascunho, publicado, agendado)
- Adicione links relacionados

## Estrutura do Projeto

```
post_pilot/
‚îú‚îÄ‚îÄ core/                   # App principal
‚îÇ   ‚îú‚îÄ‚îÄ models.py          # Theme e Post models
‚îÇ   ‚îú‚îÄ‚îÄ admin.py           # Interface admin
‚îÇ   ‚îú‚îÄ‚îÄ views.py           # Views principais
‚îÇ   ‚îú‚îÄ‚îÄ services.py        # Integra√ß√£o OpenAI
‚îÇ   ‚îî‚îÄ‚îÄ urls.py            # URLs do app
‚îú‚îÄ‚îÄ templates/core/        # Templates HTML
‚îú‚îÄ‚îÄ post_pilot/           # Configura√ß√µes Django
‚îî‚îÄ‚îÄ db.sqlite3           # Banco SQLite
```

## Modelos

### Theme
- T√≠tulo e descri√ß√£o
- T√≥picos sugeridos (JSON)
- Data de gera√ß√£o dos t√≥picos
- Status ativo/inativo

### Post
- Relacionado a um tema
- Tipo: simples ou artigo
- T√≠tulo, conte√∫do, t√≥pico
- SEO: t√≠tulo e descri√ß√£o
- Link opcional
- Status e datas de controle
- Metadados de gera√ß√£o (prompt, modelo usado)

## Admin Interface

Acesse `/admin/` para:
- Gerenciar temas e posts
- Ver estat√≠sticas
- A√ß√µes em lote (marcar como publicado/rascunho)
- Filtros por tipo, status, data

## Agentes OpenAI

### Agente 1 - Gera√ß√£o de T√≥picos
- Modelo: GPT-3.5-turbo
- Recebe tema e descri√ß√£o
- Retorna 3-5 t√≥picos espec√≠ficos em JSON

### Agente 2 - Gera√ß√£o de Conte√∫do
- Modelo: GPT-3.5-turbo (posts) / GPT-4 (artigos)
- Recebe t√≥pico e tipo de conte√∫do
- Segue templates pr√©-definidos
- Retorna t√≠tulo, conte√∫do e SEO em JSON

## URLs Principais

- `/` - Dashboard
- `/themes/` - Lista de temas
- `/themes/create/` - Criar tema
- `/themes/{id}/` - Detalhe do tema
- `/posts/` - Lista de posts
- `/posts/{id}/` - Detalhe do post
- `/admin/` - Interface administrativa

## Configura√ß√µes

Vari√°veis de ambiente no `.env`:
- `OPENAI_API_KEY` - Chave da API OpenAI (obrigat√≥ria)
- `SECRET_KEY` - Chave secreta Django (opcional para dev)

## Pr√≥ximos Passos

- Implementar agendamento de publica√ß√£o
- Integra√ß√£o com LinkedIn API
- Analytics de performance
- Templates personaliz√°veis
- Aprova√ß√£o em workflow